{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from kerastuner import HyperModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratorHyperModel(HyperModel):\n",
    "    def __init__(self, input_shape):\n",
    "        self.input_shape = input_shape\n",
    "\n",
    "    def build(self, hp):\n",
    "        # Encoder\n",
    "        input_layer = layers.Input(shape=self.input_shape)\n",
    "        x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(input_layer)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        \n",
    "        filters = hp.Int('filters', min_value=64, max_value=256, step=32)\n",
    "        x = layers.Conv2D(filters, (3, 3), strides=(2, 2), activation='relu', padding='same')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        # Transformer\n",
    "        num_residual_blocks = hp.Int('num_residual_blocks', min_value=1, max_value=10, step=1)\n",
    "        for _ in range(num_residual_blocks):\n",
    "            x = residual_block(x, filters=filters)\n",
    "\n",
    "        # Decoder\n",
    "        x = layers.Conv2DTranspose(64, (3, 3), strides=(2, 2), activation='relu', padding='same')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        output_layer = layers.Conv2D(3, (3, 3), activation='tanh', padding='same')(x)\n",
    "\n",
    "        generator_model = Model(input_layer, output_layer)\n",
    "\n",
    "        return generator_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscriminatorHyperModel(HyperModel):\n",
    "    def __init__(self, input_shape):\n",
    "        self.input_shape = input_shape\n",
    "\n",
    "    def build(self, hp):\n",
    "        input_layer = layers.Input(shape=self.input_shape)\n",
    "        \n",
    "        filters = hp.Int('filters', min_value=32, max_value=128, step=32)\n",
    "        \n",
    "        x = layers.Conv2D(filters, (3, 3), strides=(2, 2), activation='relu', padding='same')(input_layer)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Conv2D(filters * 2, (3, 3), strides=(2, 2), activation='relu', padding='same')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Conv2D(filters * 4, (3, 3), strides=(2, 2), activation='relu', padding='same')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Flatten()(x)\n",
    "        output_layer = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "        discriminator_model = Model(input_layer, output_layer)\n",
    "\n",
    "        return discriminator_model\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
